{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10: Real-world Applications\n",
    "\n",
    "In this tutorial, we'll apply the concepts learned in previous sessions to build practical, real-world applications using LangChain and LangGraph. We'll implement four different applications to showcase the versatility and power of these libraries in solving complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from langchain.llms import Groq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Set up the Groq LLM\n",
    "llm = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# Define our state structure\n",
    "class State(dict):\n",
    "    messages: List[Dict[str, str]]\n",
    "    memory: Any\n",
    "    current_step: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building a content moderation system\n",
    "\n",
    "Let's create a content moderation system that can classify text as safe or potentially harmful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a content moderation AI. Your task is to classify the following text as either 'SAFE' or 'UNSAFE'. \n",
    "    If the content contains any hate speech, explicit violence, or adult content, classify it as 'UNSAFE'. \n",
    "    Otherwise, classify it as 'SAFE'. Respond with only 'SAFE' or 'UNSAFE'.\n",
    "\n",
    "    Text to moderate: {text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "moderation_chain = LLMChain(llm=llm, prompt=moderation_prompt)\n",
    "\n",
    "def moderate_content(state: State) -> State:\n",
    "    text = state[\"messages\"][-1][\"content\"]\n",
    "    result = moderation_chain.run(text=text)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": f\"Content classification: {result}\"})\n",
    "    return state\n",
    "\n",
    "# Create the graph\n",
    "moderation_graph = StateGraph(State)\n",
    "moderation_graph.add_node(\"moderate\", moderate_content)\n",
    "moderation_graph.set_entry_point(\"moderate\")\n",
    "moderation_graph.add_edge(\"moderate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "moderation_app = moderation_graph.compile()\n",
    "\n",
    "# Test the moderation system\n",
    "initial_state = State(messages=[], memory=None, current_step=\"\")\n",
    "initial_state[\"messages\"].append({\"role\": \"human\", \"content\": \"Hello, how are you today?\"})\n",
    "for output in moderation_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])\n",
    "\n",
    "initial_state[\"messages\"] = [{\"role\": \"human\", \"content\": \"I hate everyone and wish them harm!\"}]\n",
    "for output in moderation_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing a language translation service\n",
    "\n",
    "Now, let's create a language translation service that can translate text between multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Translate the following text from {source_lang} to {target_lang}:\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Translation:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "def translate_text(state: State) -> State:\n",
    "    text = state[\"messages\"][-1][\"content\"]\n",
    "    source_lang = state[\"source_lang\"]\n",
    "    target_lang = state[\"target_lang\"]\n",
    "    result = translation_chain.run(text=text, source_lang=source_lang, target_lang=target_lang)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": f\"Translation: {result}\"})\n",
    "    return state\n",
    "\n",
    "# Create the graph\n",
    "translation_graph = StateGraph(State)\n",
    "translation_graph.add_node(\"translate\", translate_text)\n",
    "translation_graph.set_entry_point(\"translate\")\n",
    "translation_graph.add_edge(\"translate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "translation_app = translation_graph.compile()\n",
    "\n",
    "# Test the translation service\n",
    "initial_state = State(messages=[], memory=None, current_step=\"\", source_lang=\"English\", target_lang=\"French\")\n",
    "initial_state[\"messages\"].append({\"role\": \"human\", \"content\": \"Hello, how are you?\"})\n",
    "for output in translation_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])\n",
    "\n",
    "initial_state = State(messages=[], memory=None, current_step=\"\", source_lang=\"English\", target_lang=\"Spanish\")\n",
    "initial_state[\"messages\"].append({\"role\": \"human\", \"content\": \"I love learning new languages!\"})\n",
    "for output in translation_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating an automated customer support chatbot\n",
    "\n",
    "Let's build a customer support chatbot that can handle common queries and provide relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a customer support AI for a software company. Answer the following query based on these guidelines:\n",
    "    1. Be polite and professional\n",
    "    2. If you don't know the answer, say so and offer to connect the customer with a human representative\n",
    "    3. For technical issues, provide step-by-step troubleshooting instructions\n",
    "    4. For pricing or account questions, provide general information and links to relevant pages\n",
    "\n",
    "    Customer query: {query}\n",
    "\n",
    "    Your response:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "support_chain = LLMChain(llm=llm, prompt=support_prompt)\n",
    "\n",
    "def handle_query(state: State) -> State:\n",
    "    query = state[\"messages\"][-1][\"content\"]\n",
    "    result = support_chain.run(query=query)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": result})\n",
    "    return state\n",
    "\n",
    "# Create the graph\n",
    "support_graph = StateGraph(State)\n",
    "support_graph.add_node(\"handle_query\", handle_query)\n",
    "support_graph.set_entry_point(\"handle_query\")\n",
    "support_graph.add_edge(\"handle_query\", END)\n",
    "\n",
    "# Compile the graph\n",
    "support_app = support_graph.compile()\n",
    "\n",
    "# Test the customer support chatbot\n",
    "initial_state = State(messages=[], memory=None, current_step=\"\")\n",
    "initial_state[\"messages\"].append({\"role\": \"human\", \"content\": \"How do I reset my password?\"})\n",
    "for output in support_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])\n",
    "\n",
    "initial_state[\"messages\"] = [{\"role\": \"human\", \"content\": \"What are your pricing plans?\"}]\n",
    "for output in support_app.stream(initial_state):\n",
    "    print(output[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Developing a text-based game with AI-driven narrative\n",
    "\n",
    "Finally, let's create a simple text-based adventure game with an AI-driven narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    action = input(\"> \")\n",
    "    if action.lower() == \"quit\":\n",
    "        print(\"Thanks for playing!\")\n",
    "        break\n",
    "    \n",
    "    state[\"messages\"].append({\"role\": \"human\", \"content\": action})\n",
    "    for output in game_app.stream(state):\n",
    "        print(output[\"messages\"][-1][\"content\"])\n",
    "    \n",
    "    state = output  # Update the state for the next iteration\n",
    "\n",
    "# Uncomment the line below to play the game interactively\n",
    "# play_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play the game, uncomment the `play_game()` line at the end of the cell above and run it. You can then interact with the game by typing your actions. Type 'quit' to end the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've built four real-world applications using LangChain and LangGraph:\n",
    "\n",
    "1. A content moderation system\n",
    "2. A language translation service\n",
    "3. An automated customer support chatbot\n",
    "4. A text-based adventure game with AI-driven narrative\n",
    "\n",
    "These applications demonstrate the versatility and power of combining LangChain components with LangGraph flows. Here are some key takeaways:\n",
    "\n",
    "- LangChain's `LLMChain` allows for easy creation of task-specific AI assistants.\n",
    "- LangGraph's `StateGraph` enables the creation of complex, stateful workflows.\n",
    "- The combination of LangChain and LangGraph allows for the development of sophisticated AI applications that can handle a wide range of tasks.\n",
    "\n",
    "## Potential Improvements and Extensions\n",
    "\n",
    "1. Content Moderation System:\n",
    "   - Implement more fine-grained content categories (e.g., violence, hate speech, adult content)\n",
    "   - Add a confidence score to the classification\n",
    "   - Integrate with a database to log moderation decisions\n",
    "\n",
    "2. Language Translation Service:\n",
    "   - Add language detection to automatically identify the source language\n",
    "   - Implement translation memory to improve consistency across similar phrases\n",
    "   - Add support for idiomatic expressions and cultural context\n",
    "\n",
    "3. Customer Support Chatbot:\n",
    "   - Integrate with a knowledge base for more accurate responses\n",
    "   - Implement sentiment analysis to detect customer frustration\n",
    "   - Add a handoff mechanism to transfer complex queries to human agents\n",
    "\n",
    "4. Text-based Adventure Game:\n",
    "   - Implement a more complex state management system to track player inventory, health, etc.\n",
    "   - Add multiple endings based on player choices\n",
    "   - Integrate with a database to save and load game progress\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "As you continue to work with LangChain and LangGraph, consider the following:\n",
    "\n",
    "- Experiment with different LLM providers to compare performance and capabilities\n",
    "- Explore more advanced LangChain components like agents and tools\n",
    "- Implement more complex LangGraph flows with parallel processing and advanced conditional logic\n",
    "- Consider deploying these applications as web services using frameworks like FastAPI or Flask\n",
    "\n",
    "Remember to always consider ethical implications and potential biases when developing AI applications, and implement appropriate safeguards and monitoring systems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
