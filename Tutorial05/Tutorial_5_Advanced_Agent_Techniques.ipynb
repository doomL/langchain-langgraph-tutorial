{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 5: Advanced Agent Techniques and Real-World Applications\n",
        "\n",
        "In this tutorial, we'll explore advanced agent techniques in LangChain and apply them to create a sophisticated AI-powered research assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.llms import Groq\n",
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import StringPromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import GroqEmbeddings\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "import re\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize Groq LLM\n",
        "llm = Groq(model_name=\"llama2-70b-4096\")\n",
        "embeddings = GroqEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating a Custom Agent with Specialized Capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom prompt template\n",
        "template = \"\"\"You are an AI research assistant designed to help with scientific literature analysis.\n",
        "You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought: {agent_scratchpad}\"\"\"\n",
        "\n",
        "class CustomPromptTemplate(StringPromptTemplate):\n",
        "    template: str\n",
        "    tools: List[Tool]\n",
        "    \n",
        "    def format(self, **kwargs) -> str:\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
        "        return self.template.format(**kwargs)\n",
        "\n",
        "class CustomOutputParser(AgentOutputParser):\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        match = re.search(r\"Action: (.*?)[\\n]*Action Input: (.*)\", llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Implementing a Multi-Agent System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and process research papers\n",
        "loader = DirectoryLoader('research_papers/', glob=\"*.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "# Define tools for the agents\n",
        "search_tool = Tool(\n",
        "    name=\"VectorStoreSearch\",\n",
        "    func=vectorstore.similarity_search,\n",
        "    description=\"Searches the research papers for relevant information. Input should be a search query.\"\n",
        ")\n",
        "\n",
        "summarize_tool = Tool(\n",
        "    name=\"Summarize\",\n",
        "    func=lambda x: llm(f\"Summarize the following text in a concise manner: {x}\"),\n",
        "    description=\"Summarizes a given text. Input should be the text to summarize.\"\n",
        ")\n",
        "\n",
        "analyze_tool = Tool(\n",
        "    name=\"Analyze\",\n",
        "    func=lambda x: llm(f\"Analyze the following text and provide key insights: {x}\"),\n",
        "    description=\"Analyzes a given text and provides key insights. Input should be the text to analyze.\"\n",
        ")\n",
        "\n",
        "tools = [search_tool, summarize_tool, analyze_tool]\n",
        "\n",
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools=tools,\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")\n",
        "\n",
        "output_parser = CustomOutputParser()\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "research_agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain, \n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation:\"], \n",
        "    allowed_tools=[tool.name for tool in tools]\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=research_agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Developing a Context-Aware Agent with Long-Term Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "def converse_with_memory(input_text):\n",
        "    response = conversation.predict(input=input_text)\n",
        "    return response\n",
        "\n",
        "memory_tool = Tool(\n",
        "    name=\"ConversationMemory\",\n",
        "    func=converse_with_memory,\n",
        "    description=\"Accesses the conversation history and provides context-aware responses. Input should be a question or statement.\"\n",
        ")\n",
        "\n",
        "tools.append(memory_tool)\n",
        "\n",
        "context_aware_agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain, \n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation:\"], \n",
        "    allowed_tools=[tool.name for tool in tools]\n",
        ")\n",
        "\n",
        "context_aware_executor = AgentExecutor.from_agent_and_tools(agent=context_aware_agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Building a Real-World Application: AI-Powered Research Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def research_assistant(query):\n",
        "    print(f\"Research Query: {query}\\n\")\n",
        "    response = context_aware_executor.run(query)\n",
        "    print(f\"Research Assistant's Response: {response}\\n\")\n",
        "    return response\n",
        "\n",
        "# Test the AI-powered research assistant\n",
        "research_queries = [\n",
        "    \"What are the main findings on climate change impacts in the research papers?\",\n",
        "    \"Summarize the key methods used in analyzing climate data across the papers.\",\n",
        "    \"Based on the previous findings, what are the most urgent areas for future research in climate change?\",\n",
        "    \"Compare and contrast the conclusions from different papers on potential solutions to mitigate climate change.\"\n",
        "]\n",
        "\n",
        "for query in research_queries:\n",
        "    research_assistant(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we've explored advanced agent techniques in LangChain and applied them to create a sophisticated AI-powered research assistant:\n",
        "\n",
        "1. **Custom Agent Creation**: We developed a specialized agent for scientific literature analysis, demonstrating how to tailor agents for specific domains.\n",
        "\n",
        "2. **Multi-Agent System**: By combining multiple tools (search, summarize, analyze), we created a versatile system capable of handling complex research tasks.\n",
        "\n",
        "3. **Context-Aware Agent with Long-Term Memory**: We implemented a conversation memory, allowing the agent to maintain context across multiple interactions and provide more coherent and relevant responses over time.\n",
        "\n",
        "4. **Real-World Application**: We built an AI-powered research assistant that can analyze scientific papers, extract key information, and provide insights on complex topics like climate change.\n",
        "\n",
        "Key Takeaways:\n",
        "- Advanced agents can be tailored for specific domains and tasks, greatly enhancing their effectiveness.\n",
        "- Combining multiple tools and agent types allows for the creation of powerful, multi-functional AI systems.\n",
        "- Implementing memory and context awareness significantly improves the quality and coherence of agent responses over time.\n",
        "- Real-world applications of these techniques can lead to powerful AI assistants capable of handling complex, domain-specific tasks.\n",
        "\n",
        "Next Steps:\n",
        "- Experiment with different combinations of tools and agent types for your specific use cases.\n",
        "- Explore ways to further enhance the agent's memory and context understanding capabilities.\n",
        "- Consider integrating external APIs or databases to expand the agent's knowledge and capabilities.\n"
      ]
    }
  ]
}