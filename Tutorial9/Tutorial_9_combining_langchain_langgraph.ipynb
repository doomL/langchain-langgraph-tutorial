{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 9: Combining LangChain and LangGraph\n",
    "\n",
    "In this tutorial, we'll explore how to effectively combine LangChain components with LangGraph flows to create powerful, flexible AI applications. We'll build a sophisticated task planning and execution system that leverages the strengths of both libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, TypedDict, List, Any\n",
    "from langchain.llms import Groq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseMessage\n",
    "from langchain.agents import Tool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Set up the Groq LLM\n",
    "llm = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# Define our state structure\n",
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    current_step: str\n",
    "    task_list: List[str]\n",
    "    task_results: List[str]\n",
    "    memory: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Integrating LangChain components into LangGraph flows\n",
    "\n",
    "Let's start by creating some LangChain components that we'll integrate into our LangGraph flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LangChain memory component\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Create LangChain tools\n",
    "task_planner = Tool(\n",
    "    name=\"TaskPlanner\",\n",
    "    func=lambda task: llm(f\"Break down the following task into 3-5 subtasks: {task}\").content,\n",
    "    description=\"Breaks down a task into subtasks\"\n",
    ")\n",
    "\n",
    "task_executor = Tool(\n",
    "    name=\"TaskExecutor\",\n",
    "    func=lambda task: llm(f\"Execute the following task and provide a brief result: {task}\").content,\n",
    "    description=\"Executes a given task and returns the result\"\n",
    ")\n",
    "\n",
    "summarizer = Tool(\n",
    "    name=\"Summarizer\",\n",
    "    func=lambda text: llm(f\"Summarize the following text: {text}\").content,\n",
    "    description=\"Summarizes given text\"\n",
    ")\n",
    "\n",
    "# Create LangChain chains\n",
    "greeting_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=ChatPromptTemplate.from_template(\"Greet the user and ask what task they need help with today.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a conversational AI system with both libraries\n",
    "\n",
    "Now, let's create our LangGraph flow that incorporates these LangChain components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define our nodes\n",
    "def greet_and_ask(state: State) -> State:\n",
    "    response = greeting_chain.run()\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "    state[\"current_step\"] = \"plan_task\"\n",
    "    return state\n",
    "\n",
    "def plan_task(state: State) -> State:\n",
    "    task = state[\"messages\"][-1][\"content\"]\n",
    "    subtasks = task_planner.run(task).split(\"\\n\")\n",
    "    state[\"task_list\"] = subtasks\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": f\"I've broken down your task into the following subtasks:\\n{' '.join(subtasks)}\\nShall I proceed with execution?\"})\n",
    "    state[\"current_step\"] = \"get_user_confirmation\"\n",
    "    return state\n",
    "\n",
    "def get_user_confirmation(state: State) -> str:\n",
    "    response = state[\"messages\"][-1][\"content\"].lower()\n",
    "    if \"yes\" in response:\n",
    "        return \"execute_task\"\n",
    "    elif \"no\" in response:\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"Understood. Is there anything else I can help you with?\"})\n",
    "        return \"greet_and_ask\"\n",
    "    else:\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"I didn't understand that. Please answer 'yes' to proceed or 'no' to start over.\"})\n",
    "        return \"get_user_confirmation\"\n",
    "\n",
    "def execute_task(state: State) -> State:\n",
    "    if state[\"task_list\"]:\n",
    "        current_task = state[\"task_list\"].pop(0)\n",
    "        result = task_executor.run(current_task)\n",
    "        state[\"task_results\"].append(result)\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": f\"Completed subtask: {current_task}\\nResult: {result}\"})\n",
    "        state[\"current_step\"] = \"execute_task\" if state[\"task_list\"] else \"summarize_results\"\n",
    "    else:\n",
    "        state[\"current_step\"] = \"summarize_results\"\n",
    "    return state\n",
    "\n",
    "def summarize_results(state: State) -> State:\n",
    "    full_results = \"\\n\".join(state[\"task_results\"])\n",
    "    summary = summarizer.run(full_results)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": f\"Task Summary:\\n{summary}\\nIs there anything else I can help you with?\"})\n",
    "    state[\"current_step\"] = \"check_for_more_tasks\"\n",
    "    return state\n",
    "\n",
    "def check_for_more_tasks(state: State) -> str:\n",
    "    response = state[\"messages\"][-1][\"content\"].lower()\n",
    "    if \"yes\" in response:\n",
    "        return \"greet_and_ask\"\n",
    "    elif \"no\" in response:\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"Thank you for using our service. Have a great day!\"})\n",
    "        return END\n",
    "    else:\n",
    "        state[\"messages\"].append({\"role\": \"assistant\", \"content\": \"I didn't understand that. Please answer 'yes' if you need help with another task, or 'no' to end the conversation.\"})\n",
    "        return \"check_for_more_tasks\"\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"greet_and_ask\", greet_and_ask)\n",
    "workflow.add_node(\"plan_task\", plan_task)\n",
    "workflow.add_node(\"get_user_confirmation\", get_user_confirmation)\n",
    "workflow.add_node(\"execute_task\", execute_task)\n",
    "workflow.add_node(\"summarize_results\", summarize_results)\n",
    "workflow.add_node(\"check_for_more_tasks\", check_for_more_tasks)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"greet_and_ask\")\n",
    "workflow.add_edge(\"greet_and_ask\", \"plan_task\")\n",
    "workflow.add_edge(\"plan_task\", \"get_user_confirmation\")\n",
    "workflow.add_edge(\"get_user_confirmation\", \"execute_task\")\n",
    "workflow.add_edge(\"get_user_confirmation\", \"greet_and_ask\")\n",
    "workflow.add_edge(\"execute_task\", \"execute_task\")\n",
    "workflow.add_edge(\"execute_task\", \"summarize_results\")\n",
    "workflow.add_edge(\"summarize_results\", \"check_for_more_tasks\")\n",
    "workflow.add_edge(\"check_for_more_tasks\", \"greet_and_ask\")\n",
    "workflow.add_edge(\"check_for_more_tasks\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing performance in complex applications\n",
    "\n",
    "To optimize performance, we can implement caching for our LLM calls and use async operations where possible. Let's modify our setup to include these optimizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.llms import Groq\n",
    "\n",
    "# Set up caching\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "# Use async LLM\n",
    "llm_async = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# Update tools to use async operations\n",
    "task_planner = Tool(\n",
    "    name=\"TaskPlanner\",\n",
    "    func=lambda task: llm_async.agenerate([f\"Break down the following task into 3-5 subtasks: {task}\"]),\n",
    "    description=\"Breaks down a task into subtasks\"\n",
    ")\n",
    "\n",
    "task_executor = Tool(\n",
    "    name=\"TaskExecutor\",\n",
    "    func=lambda task: llm_async.agenerate([f\"Execute the following task and provide a brief result: {task}\"]),\n",
    "    description=\"Executes a given task and returns the result\"\n",
    ")\n",
    "\n",
    "summarizer = Tool(\n",
    "    name=\"Summarizer\",\n",
    "    func=lambda text: llm_async.agenerate([f\"Summarize the following text: {text}\"]),\n",
    "    description=\"Summarizes given text\"\n",
    ")"
   ]
  },
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Case study: A task planning and execution system\n",
    "\n",
    "Now that we have our optimized system set up, let's run it and see how it performs with a complex task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"current_step\": \"\",\n",
    "    \"task_list\": [],\n",
    "    \"task_results\": [],\n",
    "    \"memory\": memory\n",
    "}\n",
    "\n",
    "# Run the graph\n",
    "async def run_workflow():\n",
    "    async for output in app.astream(initial_state):\n",
    "        if \"messages\" in output and output[\"messages\"]:\n",
    "            last_message = output[\"messages\"][-1]\n",
    "            if last_message[\"role\"] == \"assistant\":\n",
    "                print(f\"Assistant: {last_message['content']}\")\n",
    "            elif last_message[\"role\"] == \"human\":\n",
    "                print(f\"Human: {last_message['content']}\")\n",
    "        \n",
    "        if output[\"current_step\"] in [\"plan_task\", \"get_user_confirmation\", \"check_for_more_tasks\"]:\n",
    "            user_input = input(\"Your response: \")\n",
    "            output[\"messages\"].append({\"role\": \"human\", \"content\": user_input})\n",
    "\n",
    "    print(\"Workflow completed.\")\n",
    "\n",
    "# Run the workflow\n",
    "import asyncio\n",
    "asyncio.run(run_workflow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our system with a complex task: \"Plan a week-long vacation to Japan\". Here's an example of how the interaction might go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simulated output. In practice, you would run the cell above and interact with the system.\n",
    "\n",
    "print(\"Assistant: Hello! What task can I help you with today?\")\n",
    "print(\"Human: I need help planning a week-long vacation to Japan.\")\n",
    "print(\"Assistant: Certainly! I'd be happy to help you plan a week-long vacation to Japan. I'll break this task down into subtasks for us to work through. Here's what I propose:\\n1. Research best times to visit Japan\\n2. Identify top destinations and attractions\\n3. Plan a day-by-day itinerary\\n4. Research accommodation options\\n5. Look into transportation within Japan\\nShall I proceed with executing these subtasks?\")\n",
    "print(\"Human: Yes, please go ahead.\")\n",
    "print(\"Assistant: Great! I'll start working on these subtasks for you.\")\n",
    "print(\"Assistant: Completed subtask: Research best times to visit Japan\\nResult: The best times to visit Japan are typically spring (March to May) for cherry blossoms and pleasant weather, and autumn (September to November) for colorful foliage and mild temperatures. Avoid the rainy season in June and the hot, humid summer months of July and August if possible.\")\n",
    "print(\"Assistant: Completed subtask: Identify top destinations and attractions\\nResult: Top destinations in Japan include Tokyo (for modern culture, shopping, and technology), Kyoto (for traditional culture, temples, and gardens), Osaka (for food and nightlife), Hiroshima (for history), and Mount Fuji (for natural beauty). Key attractions: Tokyo Skytree, Senso-ji Temple, Fushimi Inari Shrine, Osaka Castle, Hiroshima Peace Memorial, and onsen (hot springs) experiences.\")\n",
    "print(\"Assistant: Completed subtask: Plan a day-by-day itinerary\\nResult: Day 1-3: Tokyo (explore neighborhoods, visit temples, experience modern culture)\\nDay 4-5: Kyoto (visit historic sites, enjoy traditional cuisine)\\nDay 6: Day trip to Mount Fuji or Osaka\\nDay 7: Return to Tokyo for departure, last-minute shopping and experiences\")\n",
    "print(\"Assistant: Completed subtask: Research accommodation options\\nResult: Options range from traditional ryokans to modern hotels and budget-friendly hostels. In Tokyo, consider areas like Shinjuku or Shibuya for convenience. In Kyoto, staying in the Gion district offers a traditional atmosphere. Book in advance, especially during peak seasons.\")\n",
    "print(\"Assistant: Completed subtask: Look into transportation within Japan\\nResult: The Japan Rail Pass is highly recommended for tourists, offering unlimited travel on JR trains, including most shinkansen (bullet trains). Within cities, subway systems are efficient. Consider renting a bicycle in Kyoto for local exploration. Taxis are available but can be expensive.\")\n",
    "print(\"Assistant: Task Summary:\\nYour week-long vacation to Japan has been planned with a focus on experiencing both modern and traditional aspects of Japanese culture. The best times to visit are spring or autumn for optimal weather. Your itinerary includes 3 days in Tokyo, 2 days in Kyoto, a day trip to Mount Fuji or Osaka, and a final day in Tokyo. Key attractions have been identified in each location. Accommodation options range from ryokans to modern hotels, with recommendations for areas to stay in each city. For transportation, the Japan Rail Pass is recommended for inter-city travel, with subways and possibly bicycles for local transportation. Remember to book accommodations in advance, especially during peak seasons.\\n\\nIs there anything else I can help you with regarding your Japan trip planning?\")\n",
    "print(\"Human: No, that's all. Thank you!\")\n",
    "print(\"Assistant: Thank you for using our service. Have a great day!\")\n",
    "print(\"Workflow completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've demonstrated how to effectively combine LangChain components with LangGraph flows to create a sophisticated task planning and execution system. We've covered:\n",
    "\n",
    "1. Integrating LangChain components (Tools, Chains, and Memory) into a LangGraph flow\n",
    "2. Building a conversational AI system that can handle complex, multi-step tasks\n",
    "3. Optimizing performance using caching and async operations\n",
    "4. A case study of planning a week-long vacation to Japan\n",
    "\n",
    "This combined approach allows for the creation of powerful, flexible AI applications that can handle a wide range of tasks. By leveraging the strengths of both LangChain and LangGraph, we can create systems that are both highly capable and easy to extend and maintain.\n",
    "\n",
    "Some potential improvements and extensions to this system could include:\n",
    "- Adding more specialized tools for different types of tasks\n",
    "- Implementing more advanced error handling and fallback strategies\n",
    "- Integrating external APIs for real-time data (e.g., weather, flight information)\n",
    "- Expanding the memory capabilities to allow for longer-term context retention\n",
    "\n",
    "As you continue to work with LangChain and LangGraph, experiment with different combinations of components and flow structures to find the best approach for your specific use cases."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}