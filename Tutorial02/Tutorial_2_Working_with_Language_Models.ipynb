{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Working with Language Models in LangChain\n",
    "\n",
    "In this tutorial, we'll explore how to work with language models in LangChain, focusing on the Groq LLM. We'll cover connecting to the model, creating prompt templates, building chains, and handling responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connecting to Language Models\n",
    "\n",
    "First, let's set up our environment and connect to the Groq LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello. How can I assist you today?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 39, 'total_tokens': 49, 'completion_time': 0.04, 'prompt_time': 0.007011686, 'queue_time': 0.014202011, 'total_time': 0.047011686}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None} id='run-6adbb062-bbed-499a-97d7-15c574792650-0' usage_metadata={'input_tokens': 39, 'output_tokens': 10, 'total_tokens': 49}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "llm = ChatGroq(\n",
    "        model_name=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.1,\n",
    "        model_kwargs={\"top_p\": 0.2, \"seed\": 1337}\n",
    "    )\n",
    "\n",
    "# Test the connection\n",
    "response = llm.invoke(\"Hello, world!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Prompt Templates\n",
    "\n",
    "Prompt templates allow us to create reusable prompts with input variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question:\n",
      "You answers in the English language.\n",
      "Question: What is the capital of France?\n",
      "Answer: Let's approach this step-by-step:\n"
     ]
    }
   ],
   "source": [
    "# Define a simple prompt template\n",
    "template = \"\"\"Answer the following question:\n",
    "You answers in the {language} language.\n",
    "Question: {question}\n",
    "Answer: Let's approach this step-by-step:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\",\"language\"])\n",
    "\n",
    "# Use the prompt template\n",
    "question = \"What is the capital of France?\"\n",
    "formatted_prompt = prompt.format(question=question,language=\"English\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Simple Prompt Chains\n",
    "\n",
    "Now, let's create a chain that combines our prompt template with the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approchons cela étape par étape :\n",
      "\n",
      "La vitesse de la lumière est une constante physique fondamentale qui représente la vitesse à laquelle la lumière se propage dans le vide. Elle est notée c et est exprimée en mètres par seconde (m/s).\n",
      "\n",
      "La vitesse de la lumière est de 299 792 458 mètres par seconde. Cette valeur a été déterminée avec une grande précision grâce à des expériences et des mesures précises.\n",
      "\n",
      "Il est important de noter que la vitesse de la lumière est une constante universelle, ce qui signifie qu'elle est la même partout dans l'univers et qu'elle ne dépend pas de la vitesse de l'observateur ou de la source de lumière.\n"
     ]
    }
   ],
   "source": [
    "# Create a chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"question\":\"What is the speed of light?\",\"language\":\"French\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Model Responses\n",
    "\n",
    "Let's explore different ways to handle and process model responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: content='Here are three prime numbers:\\n\\n1. 7\\n2. 11\\n3. 23' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 40, 'total_tokens': 61, 'completion_time': 0.084, 'prompt_time': 0.007700269, 'queue_time': 0.030701834, 'total_time': 0.091700269}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None} id='run-c6302169-d8f7-4d6d-ba1e-15b92ab3b158-0' usage_metadata={'input_tokens': 40, 'output_tokens': 21, 'total_tokens': 61}\n",
      "\n",
      "Chain response: Pour commencer, voici quelques noms d'arbres courants en français :\n",
      "\n",
      "1. Arbre fruitier : Pommier (Pomme), Pêcher (Pêche), Cerisier (Cerise)\n",
      "2. Arbre à feuilles : Chêne, Hêtre, Érable\n",
      "3. Arbre à aiguilles : Pin, Sapin, Épicéa\n",
      "4. Arbre tropical : Palmier, Cocotier, Manglier\n",
      "5. Arbre ornemental : Lilas, Fleur d'oranger, Magnolia\n",
      "\n",
      "Voici quelques autres exemples :\n",
      "\n",
      "* Le chêne est un arbre robuste et durable.\n",
      "* Le pommier est un arbre fruitier très répandu.\n",
      "* Le pin est un arbre à aiguilles qui pousse dans les régions montagneuses.\n",
      "* Le palmier est un arbre tropical qui pousse dans les régions chaudes.\n",
      "\n",
      "J'espère que cela vous aidera !\n"
     ]
    }
   ],
   "source": [
    "# Get the raw response\n",
    "raw_response = llm.invoke(\"List three prime numbers.\")\n",
    "print(\"Raw response:\", raw_response)\n",
    "\n",
    "# Using the chain with a dictionary input\n",
    "chain_response = chain.invoke({\"question\": \"tree Names\",\"language\": \"French\"})\n",
    "print(\"\\nChain response:\", chain_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "Parsed list: ['Red', 'Orange', 'Yellow', 'Green', 'Blue', 'Indigo', 'Violet', 'Pink', 'Brown', 'Grey', 'Black', 'White', 'Turquoise', 'Silver', 'Gold', 'Copper', 'Bronze', 'Beige', 'Cream', 'Ivory', 'Lavender', 'Peach', 'Magenta', 'Cyan', 'Teal', 'Coral', 'Salmon', 'Maroon', 'Navy', 'Purple', 'Olive', 'Lime', 'Mint', 'Aqua', 'Fuchsia', 'Charcoal', 'Taupe', 'Mocha', 'Sage', 'Seafoam', 'Periwinkle', 'Plum', 'Burgundy', 'Onyx', 'Ruby', 'Emerald', 'Garnet', 'Amethyst', 'Jade', 'Cobalt', 'Cerulean', 'Azure', 'Sapphire', 'Tangerine', 'Lemon', 'Powder Blue', 'Rose', 'Blush', 'Mauve', 'Sienna', 'Umber', 'Terracotta', 'Carmine', 'Crimson', 'Scarlet', 'Vermilion', 'Coral Red', 'Russet', 'Clay', 'Sand', 'Khaki', 'Tan', 'Caramel', 'Honey', 'Mustard', 'Sienna Brown', 'Mahogany', 'Walnut', 'Ebony', 'Ivory Black', 'Pearl', 'Opal', 'Amaranth', 'Caput Mortuum', 'Carmine Red', 'Celadon', 'Cerise', 'Cinnabar', 'Cochineal', 'Gamboge', 'Heliotrope', 'Smalt', \"Scheele's Green\", 'Rose Madder', 'Tyrian Purple', 'Vantablack', 'Viridian', 'Woad', 'Xanadu', 'Yellow Ochre', 'Zaffre', 'Bistre', 'Burnt Sienna', 'Burnt Umber', 'Capri', 'Cardinal Red', 'Carmine Lake', 'Carrot Orange', 'Celadon Green', 'Cerulean Blue', 'Chrome Yellow', 'Citrine', 'Cobalt Blue', 'Congo Red', 'Coral Pink', 'Cornflower Blue', 'Crimson Lake', 'Cyanine', 'Dandelion', 'Delft Blue', 'Denim', 'Desert Sand', 'Dioxazine', 'Dusky Pink', 'Ecru', 'Eucalyptus', 'Fallow', 'Fawn', 'Fern', 'Field Drab', 'Fire Engine Red', 'Flame', 'Flax', 'Forest Floor', 'Fuchsia Pink', 'Gamboge Yellow', 'Garnet Red', 'Golden Brown', 'Goldenrod', 'Grass Green', 'Green Bice', 'Green Blue', 'Green Gold', 'Green Yellow', 'Grotto', 'Gunmetal', 'Helianthus', 'Holly Green', \"Hooker's Green\", 'Imperial Blue', 'Imperial Purple', 'Incarnadine', 'Indian Red', 'International Klein Blue', 'International Orange', 'Iris', 'Iron Oxide Red', 'Ivory Black', 'Jade Green', 'Jasmine', 'Jonquil', 'Kelly Green', 'Kenyan Copper', 'Key Lime', 'Khaki Green', 'La Vie En Rose', 'Lapis Lazuli', 'Laurel Green', 'Lavender Grey', 'Lemon Chiffon', 'Lilac', 'Lime Rickey', 'Linen', 'Loden', 'London Fog', 'Mahogany Red', 'Maize', 'Mallow', 'Manganese Blue', 'Marigold', 'Maroon Brown', 'Mauveine', 'Maya Blue', 'Meissen Blue', 'Melon', 'Merlot', 'Midnight Blue', 'Midnight Green', 'Mocha Brown', 'Mummy Brown', 'Mustard Brown', 'Mustard Green', 'Mustard Yellow', 'Naples Yellow', 'Nattier Blue', 'Nickel', 'Nile Blue', 'Nile Green', 'Non Photo Blue', 'Ochre', 'Old Gold', 'Old Lace', 'Olive Brown', 'Olive Drab', 'Olive Green', 'Onyx Black', 'Opaline', 'Orange Red', 'Orange Yellow', 'Orchid', 'Oxblood', 'Pacific Blue', 'Pale Aqua', 'Pale Blue', 'Pale Gold', 'Pale Lavender', 'Pale Lilac', 'Pale Magenta', 'Pale Pink', 'Pale Powder Blue', 'Pale Silver', 'Pale Turquoise', 'Pale Violet', 'Paprika', 'Paris Green', 'Parma Violet', 'Peach', 'Pearl White', 'Periwinkle Blue', 'Persian Blue', 'Persian Green', 'Persian Red', 'Phthalo Blue', 'Phthalo Green', 'Phthalo Yellow', 'Pigeon Blue', 'Pine Green', 'Pink', 'Pinkish Grey', 'Pistachio', 'Platinum', 'Plum', 'Pomegranate', 'Poppy Red', 'Porcelain', 'Powder Pink', 'Prussian Blue', 'Prussian Green', 'Prussian Red', 'Puce', 'Pumpkin', 'Purple Brown', 'Purple Grey', 'Purple Lake', 'Purple Pink', 'Purple Red', 'Quinacridone Red', 'Quinacridone Violet', 'Quinacridone Yellow', 'Radicchio', 'Raspberry', 'Raw Sienna', 'Raw Umber', 'Red Brown', 'Red Gold', 'Red Ochre', 'Red Orange', 'Red Pink', 'Red Violet', 'Red Yellow', 'Reseda', 'Rhodamine', 'Rich Gold', \"Robin's Egg Blue\", 'Rose Madder', 'Rose Pink', 'Rose Red', 'Rose Violet', 'Rosewood', 'Rosy Brown', 'Royal Blue', 'Royal Purple', 'Ruby Red', 'Ruddy', 'Rufous', 'Russet Brown', 'Rust', 'Saffron', 'Sage Green', 'Salmon Pink', 'Sandy Beige', 'Sapphire Blue', 'Scarlet Lake', \"Scheele's Green\", 'School Bus Yellow', 'Sea Green', 'Seafoam Green', 'Sepia', 'Sepia Brown', 'Sepia Red', 'Shadow', 'Shamrock Green', 'Shrimp Pink', 'Sienna Brown', 'Silver Grey', 'Silver Pink', 'Silver White', 'Sinopia', 'Sky Blue', 'Slate Blue', 'Slate Grey', 'Smalt Blue', 'Smoke', 'Snow', 'Soft Peach', 'Soft Pink', 'Soft Sage', 'Sorrel', 'Soursop', 'Space Blue', 'Sparrow', 'Spinach', 'Spruce', \"St. Patrick's Blue\", 'Steel Blue', 'Steel Grey', 'Steel Pink', 'Steel White', 'Stone', 'Straw', 'Strawberry', 'Sugar Pink', 'Sulphur', 'Sunset Orange', 'Sunset Yellow', 'Tallow', 'Tangerine Yellow', 'Tansy', 'Taupe Brown', 'Taupe Grey', 'Tea Green', 'Tea Rose', 'Teal Blue', 'Teal Green', 'Terra Cotta', 'Terra Verte', 'Thistle', 'Thulian Pink', 'Tiffany Blue', 'Timberwolf', 'Titanium White', 'Tomato Red', 'Tourmaline', 'Tumbleweed', 'Turquoise Blue', 'Turquoise Green', 'Tyrian Purple', 'Umber Brown', 'Umber Red', 'Umber Yellow', 'Uranium Yellow', 'Vantablack', 'Venetian Red', 'Verdigris', 'Vermilion', 'Vermilion Red', 'Violet Blue', 'Violet Brown', 'Violet Grey', 'Violet Pink', 'Violet Red', 'Violet Yellow', 'Viridian Green', 'Viridian Grey', 'Wagon Wheel', 'Walnut Brown', 'Warm Beige', 'Warm Grey', 'Warm Red', 'Watermelon Pink', 'Wenge', 'Wheat', 'White Smoke', 'Wild Strawberry', 'Willow', 'Wine', 'Wine Red', 'Wisteria', 'Wood Brown', 'Xanadu', 'Xanadu Grey', 'Xanadu Pink', 'Xanadu Purple', 'Xanadu Red', 'Xanadu Yellow', 'Yellow Brown', 'Yellow Green', 'Yellow Ochre', 'Yellow Pink', 'Yellow Red', 'Yellow Violet', 'Yellow White', 'Zaffre Blue', 'Zinnia']\n"
     ]
    }
   ],
   "source": [
    "# Parsing structured output\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "list_prompt = PromptTemplate(\n",
    "    template=\"List 100 {item}. {format_instructions} write only the colors, nothing else\",\n",
    "    input_variables=[\"item\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chain = list_prompt | llm |output_parser\n",
    "result = chain.invoke({\"item\":\"colors\"})\n",
    "print(type(result))\n",
    "print(\"\\nParsed list:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices for Prompt Engineering\n",
    "\n",
    "Here are some best practices for effective prompt engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------\n",
      "Specific Prompt Result:\n",
      "Quantum entanglement is a fascinating concept in physics that can be a bit tricky to grasp, but I'll try to explain it in simple terms.\n",
      "\n",
      "**What is Quantum Entanglement?**\n",
      "\n",
      "Imagine you have two toy cars that are connected by a spring. If you push one car, the other car will move too, because they're connected by the spring. This is a classical example of how two objects can be connected and affect each other.\n",
      "\n",
      "Now, imagine that these toy cars are not connected by a spring, but they're still somehow \"linked\" in a way that lets them affect each other, even if they're on opposite sides of the universe. This is roughly what quantum entanglement is.\n",
      "\n",
      "**How Does it Work?**\n",
      "\n",
      "In the quantum world, tiny particles like atoms and electrons can become \"entangled\" in a way that lets them affect each other, even if they're separated by huge distances. When two particles are entangled, their properties (like spin, energy, or momentum) become connected in a way that can't be explained by classical physics.\n",
      "\n",
      "Here's an example: imagine two entangled particles, A and B. If particle A is spinning clockwise, particle B will instantly start spinning counterclockwise, even if they're on opposite sides of the universe. This happens even if there's no physical connection between them, and even if they're separated by billions of kilometers.\n",
      "\n",
      "**The Weird Part**\n",
      "\n",
      "The really weird thing about quantum entanglement is that it happens instantly, no matter how far apart the particles are. This means that information can travel between entangled particles faster than the speed of light, which is a fundamental limit in classical physics.\n",
      "\n",
      "**What Does it Mean?**\n",
      "\n",
      "Quantum entanglement is a fundamental aspect of quantum mechanics, and it has been experimentally confirmed many times. It shows that the quantum world is a strange and non-intuitive place, where particles can be connected in ways that defy classical understanding.\n",
      "\n",
      "Entanglement has many potential applications, including quantum computing, quantum cryptography, and even quantum teleportation (which is a way of transferring information from one particle to another without physical transport).\n",
      "\n",
      "I hope this explanation helped you understand quantum entanglement in simple terms!\n",
      "\n",
      "---------------------------------------------------\n",
      "Few-shot Prompt Result:\n",
      "Sentiment: Neutral\n",
      "\n",
      "The text expresses a neutral sentiment because it doesn't convey strong emotions or opinions. The phrase \"This movie was okay\" suggests a mediocre experience, and the addition of \"I guess\" further emphasizes the speaker's ambivalence.\n",
      "\n",
      "---------------------------------------------------\n",
      "Step-by-step Prompt Result:\n",
      "To solve the problem 'Calculate the area of a circle with radius 5 cm', I will follow the given steps:\n",
      "\n",
      "1. Identify the key information:\n",
      "The key information in this problem is the radius of the circle, which is 5 cm.\n",
      "\n",
      "2. Determine the appropriate formula or method:\n",
      "The formula to calculate the area of a circle is A = πr², where A is the area and r is the radius of the circle.\n",
      "\n",
      "3. Apply the formula or method step-by-step:\n",
      "Using the formula A = πr², we can substitute the given radius (r = 5 cm) into the formula:\n",
      "A = π(5)²\n",
      "A = π(25)\n",
      "A = 3.14159... * 25\n",
      "A ≈ 78.54\n",
      "\n",
      "4. Check your answer:\n",
      "The calculated area of the circle is approximately 78.54 square centimeters. This answer seems reasonable, as the area of a circle with a radius of 5 cm should be greater than the area of a square with a side length of 5 cm (which is 25 square centimeters).\n"
     ]
    }
   ],
   "source": [
    "# 1. Be specific and provide context\n",
    "specific_prompt = PromptTemplate(\n",
    "    template=\"You are an expert in {field}. Explain {concept} in simple terms for a beginner.\",\n",
    "    input_variables=[\"field\", \"concept\"]\n",
    ")\n",
    "\n",
    "# 2. Use examples (few-shot learning)\n",
    "few_shot_prompt = PromptTemplate(\n",
    "    template=\"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
    "\n",
    "Example 1:\n",
    "Text: I love this product!\n",
    "Sentiment: Positive\n",
    "\n",
    "Example 2:\n",
    "Text: This is the worst experience ever.\n",
    "Sentiment: Negative\n",
    "\n",
    "Example 3:\n",
    "Text: The weather is cloudy today.\n",
    "Sentiment: Neutral\n",
    "\n",
    "Now, classify the following text:\n",
    "Text: {text}\n",
    "Sentiment:\"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# 3. Break complex tasks into steps\n",
    "step_prompt = PromptTemplate(\n",
    "    template=\"\"\"To solve the problem '{problem}', follow these steps:\n",
    "1. Identify the key information\n",
    "2. Determine the appropriate formula or method\n",
    "3. Apply the formula or method step-by-step\n",
    "4. Check your answer\n",
    "\n",
    "Now, solve the problem:\"\"\",\n",
    "    input_variables=[\"problem\"]\n",
    ")\n",
    "\n",
    "# Test the prompts\n",
    "chains = {\n",
    "    \"Specific\": specific_prompt | llm,\n",
    "    \"Few-shot\": few_shot_prompt | llm,\n",
    "    \"Step-by-step\": step_prompt | llm \n",
    "    }\n",
    "\n",
    "for name, chain in chains.items():\n",
    "    print(f\"\\n---------------------------------------------------\\n{name} Prompt Result:\")\n",
    "    if name == \"Specific\":\n",
    "        print(chain.invoke({\"field\":\"physics\", \"concept\":\"quantum entanglement\"}).content)\n",
    "    elif name == \"Few-shot\":\n",
    "        print(chain.invoke({\"text\":\"This movie was okay, I guess.\"}).content)\n",
    "    else:\n",
    "        print(chain.invoke({\"problem\":\"Calculate the area of a circle with radius 5 cm\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've explored various aspects of working with language models in LangChain, including connecting to models, creating prompt templates, building chains, handling responses, and implementing best practices for prompt engineering. These skills will serve as a foundation for building more complex applications with LangChain in future tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
