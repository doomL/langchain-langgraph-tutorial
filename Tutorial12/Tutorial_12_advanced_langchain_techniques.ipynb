{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 12: Advanced LangChain Techniques\n",
    "\n",
    "In this tutorial, we'll explore advanced LangChain techniques, including custom chain development, advanced prompt engineering, retrieval-augmented generation (RAG), and fine-tuning language models for specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.llms import Groq\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain, TransformChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Set up the Groq LLM\n",
    "llm = Groq(api_key=os.environ[\"GROQ_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom chain development\n",
    "\n",
    "Let's create a custom chain that processes text through multiple steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessingChain(Chain):\n",
    "    input_key: str = \"input_text\"\n",
    "    output_key: str = \"processed_text\"\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return [self.input_key]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return [self.output_key]\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        text = inputs[self.input_key]\n",
    "        \n",
    "        # Step 1: Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Step 2: Remove punctuation\n",
    "        text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "        \n",
    "        # Step 3: Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return {self.output_key: text}\n",
    "\n",
    "# Use the custom chain\n",
    "text_processor = TextProcessingChain()\n",
    "result = text_processor.run(\"Hello, World! This is a   TEST.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt templating and management\n",
    "\n",
    "Let's explore advanced prompt templating techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a complex prompt template\n",
    "complex_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant specializing in {domain}.\"),\n",
    "    (\"human\", \"I need help with the following task: {task}\"),\n",
    "    (\"ai\", \"Certainly! I'd be happy to help you with that. Could you provide more details about {detail_request}?\"),\n",
    "    (\"human\", \"Here's more information: {additional_info}\"),\n",
    "    (\"ai\", \"Thank you for the additional information. Based on what you've told me, here's my response:\"),\n",
    "])\n",
    "\n",
    "# Create a chain using the complex prompt\n",
    "complex_chain = LLMChain(llm=llm, prompt=complex_prompt)\n",
    "\n",
    "# Run the chain\n",
    "result = complex_chain.run({\n",
    "    \"domain\": \"software development\",\n",
    "    \"task\": \"optimizing a slow database query\",\n",
    "    \"detail_request\": \"the current query structure and database schema\",\n",
    "    \"additional_info\": \"The query is a JOIN operation across three tables with multiple WHERE clauses. The database is PostgreSQL.\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing retrieval-augmented generation (RAG)\n",
    "\n",
    "Let's implement a simple RAG system using FAISS and HuggingFace embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the document\n",
    "loader = TextLoader(\"path/to/your/document.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Define the RAG prompt\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=\"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer: \"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def retrieve_and_generate(query: str) -> str:\n",
    "    # Retrieve relevant documents\n",
    "    docs = db.similarity_search(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Generate answer\n",
    "    chain = LLMChain(llm=llm, prompt=rag_prompt)\n",
    "    return chain.run({\"context\": context, \"question\": query})\n",
    "\n",
    "# Test the RAG system\n",
    "result = retrieve_and_generate(\"What is the capital of France?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning language models for specific tasks\n",
    "\n",
    "While we can't directly fine-tune the Groq model, we can simulate fine-tuning by creating a specialized prompt that adapts the model's behavior for a specific task. Let's create a 'fine-tuned' model for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": [],
   "source": [
    "sentiment_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a sentiment analysis expert. Your task is to analyze the sentiment of the given text and classify it as positive, negative, or neutral. \n",
    "    Provide a brief explanation for your classification.\n",
    "\n",
    "    Text: {input_text}\n",
    "\n",
    "    Sentiment: \"\"\",\n",
    "    input_variables=[\"input_text\"]\n",
    ")\n",
    "\n",
    "sentiment_chain = LLMChain(llm=llm, prompt=sentiment_prompt)\n",
    "\n",
    "def analyze_sentiment(text: str) -> str:\n",
    "    return sentiment_chain.run(text)\n",
    "\n",
    "# Test the 'fine-tuned' sentiment analysis model\n",
    "texts = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",\n",
    "    \"This is the worst experience I've ever had. Terrible customer service.\",\n",
    "    \"The weather is quite nice today, not too hot or cold.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {analyze_sentiment(text)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've explored advanced LangChain techniques, including:\n",
    "\n",
    "1. Custom chain development for specialized text processing\n",
    "2. Advanced prompt templating and management for complex interactions\n",
    "3. Implementing a retrieval-augmented generation (RAG) system\n",
    "4. Simulating fine-tuning for specific tasks using specialized prompts\n",
    "\n",
    "These techniques allow you to create more sophisticated and tailored AI applications using LangChain and LangGraph.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To further advance your skills with LangChain and LangGraph, consider:\n",
    "\n",
    "1. Experimenting with more complex custom chains and combining them with LangGraph flows\n",
    "2. Developing a prompt management system for large-scale applications\n",
    "3. Exploring advanced RAG techniques, such as hypothetical document embeddings or multi-query retrieval\n",
    "4. Investigating ways to evaluate and improve the performance of your 'fine-tuned' models\n",
    "5. Integrating these advanced techniques into a full-fledged application"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}